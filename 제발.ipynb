{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.path import Path\n",
    "from torchvision.transforms import v2 as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset:\n",
    "    def __init__(self, folder_path, transforms=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transforms = transforms\n",
    "        self.data_pairs = self._load_data_pairs()\n",
    "\n",
    "    def _load_data_pairs(self):\n",
    "        image_files = []\n",
    "        json_files = {}\n",
    "        data_pairs = []\n",
    "\n",
    "        # 폴더를 재귀적으로 검색하여 이미지 파일과 JSON 파일 목록을 생성\n",
    "        for root, _, files in os.walk(self.folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "                elif file.endswith(\".json\"):\n",
    "                    json_files[os.path.splitext(file)[0]] = os.path.join(root, file)\n",
    "\n",
    "        # 진행률 표시줄 추가\n",
    "        for image_file_path in tqdm(image_files, desc=\"Matching image and JSON files\"):\n",
    "            # 이미지 파일 이름에서 확장자를 제외한 부분 가져오기\n",
    "            image_name = os.path.splitext(os.path.basename(image_file_path))[0]\n",
    "        \n",
    "            # 해당 이미지 파일과 매칭되는 JSON 파일 찾기\n",
    "            if image_name in json_files:\n",
    "                json_file_path = json_files[image_name]\n",
    "                data_pairs.append((image_file_path, json_file_path))\n",
    "            else:\n",
    "                print(f\"JSON file not found for image: {image_file_path}\")\n",
    "        \n",
    "        return data_pairs\n",
    "\n",
    "    def create_detr_target(self, json_data):\n",
    "        annotations = json_data['annotations']\n",
    "        categories = {cat['id']: cat['name'] for cat in json_data['categories']}\n",
    "        \n",
    "        # 한글에서 영어로 라벨을 매핑하는 딕셔너리\n",
    "        label_mapping = {'화방': \"buds\", '줄기': \"stem\", '잎': \"leaf\", '열매': \"fruit\"}\n",
    "\n",
    "        height = 1960  # 로즈 테스트시 고정값 사용\n",
    "        width = float(json_data['images'][0]['width'])\n",
    "\n",
    "        target = {\n",
    "            'boxes': [],\n",
    "            'labels': [],\n",
    "            'area': [],\n",
    "            'iscrowd': [],\n",
    "        }\n",
    "\n",
    "        for ann in annotations:\n",
    "            bbox = ann['bbox']\n",
    "            obj_name = categories[ann['category_id']]\n",
    "            \n",
    "            # 한글 카테고리 이름을 영어로 변환\n",
    "            label = label_mapping.get(obj_name, \"unknown\")\n",
    "\n",
    "            # 바운딩 박스 좌표 변환 및 정규화\n",
    "            x_min = bbox[1] / width\n",
    "            y_min = (height-(bbox[0]+bbox[2])) / height\n",
    "            box_width = bbox[3] / width\n",
    "            box_height = bbox[2] / height\n",
    "            \n",
    "            target['boxes'].append([x_min, y_min, box_width, box_height])\n",
    "            target['area'].append(ann['area'])\n",
    "            target['iscrowd'].append(ann['isCrowd'])\n",
    "            target['labels'].append(label)\n",
    "\n",
    "        # 리스트를 텐서로 변환\n",
    "        target['boxes'] = torch.tensor(target['boxes'], dtype=torch.float32)\n",
    "        target['area'] = torch.tensor(target['area'], dtype=torch.float32)\n",
    "        target['iscrowd'] = torch.tensor(target['iscrowd'], dtype=torch.int64)\n",
    "\n",
    "        return target\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, json_path = self.data_pairs[index]\n",
    "\n",
    "        with open(json_path, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        target = self.create_detr_target(json_data)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching image and JSON files: 100%|██████████| 411/411 [00:00<00:00, 206178.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 411\n",
      "target: {'boxes': tensor([1287.7600,  648.5200, 2196.7100, 1641.3600]), 'labels': tensor(3)}\n",
      "Type of target: <class 'dict'>\n",
      "img: tensor([[[0.8784, 0.9176, 0.9569,  ..., 0.1647, 0.1647, 0.1725],\n",
      "         [0.8941, 0.9176, 0.9412,  ..., 0.1608, 0.1647, 0.1686],\n",
      "         [0.9137, 0.9412, 0.9373,  ..., 0.1647, 0.1569, 0.1608],\n",
      "         ...,\n",
      "         [0.7176, 0.4078, 0.3490,  ..., 0.4863, 0.3882, 0.2863],\n",
      "         [0.7176, 0.4118, 0.3490,  ..., 0.4863, 0.3843, 0.2824],\n",
      "         [0.7176, 0.4196, 0.3490,  ..., 0.4863, 0.3804, 0.2824]],\n",
      "\n",
      "        [[0.8902, 0.9294, 0.9686,  ..., 0.2588, 0.2667, 0.2706],\n",
      "         [0.9098, 0.9294, 0.9529,  ..., 0.2588, 0.2667, 0.2706],\n",
      "         [0.9294, 0.9529, 0.9451,  ..., 0.2627, 0.2588, 0.2627],\n",
      "         ...,\n",
      "         [0.7412, 0.4588, 0.3882,  ..., 0.4941, 0.4078, 0.3216],\n",
      "         [0.7412, 0.4549, 0.3882,  ..., 0.4941, 0.4000, 0.3098],\n",
      "         [0.7412, 0.4627, 0.3882,  ..., 0.4980, 0.3961, 0.3020]],\n",
      "\n",
      "        [[0.9255, 0.9608, 0.9922,  ..., 0.1059, 0.1137, 0.1216],\n",
      "         [0.9529, 0.9725, 0.9882,  ..., 0.1059, 0.1137, 0.1176],\n",
      "         [0.9804, 0.9961, 0.9922,  ..., 0.1098, 0.1098, 0.1098],\n",
      "         ...,\n",
      "         [0.7333, 0.4745, 0.4196,  ..., 0.4706, 0.3725, 0.2745],\n",
      "         [0.7373, 0.4745, 0.4196,  ..., 0.4667, 0.3686, 0.2824],\n",
      "         [0.7333, 0.4784, 0.4196,  ..., 0.4667, 0.3686, 0.2863]]])\n",
      "Type of img: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 및 변환 정의\n",
    "\n",
    "normalize = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        T.ConvertImageDtype(torch.float32)\n",
    "    ])\n",
    "\n",
    "\n",
    "folder_path = \"./Dataset\"\n",
    "transform_train = T.Compose([\n",
    "    normalize\n",
    "])\n",
    "transform_test =  T.Compose([\n",
    "    normalize\n",
    "])\n",
    "dataset = CustomDataset(folder_path, transforms=transform_train)\n",
    "dataset_test = CustomDataset(folder_path, transforms=transform_test)\n",
    "\n",
    "# 학습 및 검증 데이터로더 정의\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-100])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-100:])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    "  \n",
    ")\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching image and JSON files: 100%|██████████| 411/411 [00:00<00:00, 206129.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "def plot_detection(img, target):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    # 이미지 형태 변경\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    # 변경된 이미지로 시각화\n",
    "    ax.imshow(img)\n",
    "\n",
    "    boxes = target['boxes'].numpy()\n",
    "    labels = target['labels']\n",
    "\n",
    "    height, width = img.shape[0], img.shape[1]  # 이미지의 높이와 너비 가져오기\n",
    "\n",
    "    for box, label in zip(boxes, labels):\n",
    "        x_min, y_min, box_width, box_height = box\n",
    "        x_min *= width\n",
    "        y_min *= height\n",
    "        box_width *= width\n",
    "        box_height *= height\n",
    "\n",
    "        rect = patches.Rectangle((x_min, y_min), box_width, box_height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        plt.text(x_min, y_min, label, color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 내용 확인 및 시각화\n",
    "for i in range(len(dataset)):\n",
    "    img, target = dataset[i]\n",
    "    print(f\"Image {i}:\", img)\n",
    "    print(f\"Target {i}:\", target)\n",
    "    plot_detection(img, target)\n",
    "    if i == 2:  # 예시로 처음 3개 항목만 확인\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
