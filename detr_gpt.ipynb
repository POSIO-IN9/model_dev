{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.path import Path\n",
    "from torchvision.transforms import v2 as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CustomDataset:\n",
    "    def __init__(self, folder_path, transforms=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transforms = transforms\n",
    "        self.data_pairs = self._load_data_pairs()\n",
    "        self.image_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "    def _load_data_pairs(self):\n",
    "        image_files = []\n",
    "        json_files = {}\n",
    "        data_pairs = []\n",
    "\n",
    "        # 폴더를 재귀적으로 검색하여 이미지 파일과 JSON 파일 목록을 생성\n",
    "        for root, _, files in os.walk(self.folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "                elif file.endswith(\".json\"):\n",
    "                    json_files[os.path.splitext(file)[0]] = os.path.join(root, file)\n",
    "\n",
    "        # 진행률 표시줄 추가\n",
    "        for image_file_path in tqdm(image_files, desc=\"Matching image and JSON files\"):\n",
    "            # 이미지 파일 이름에서 확장자를 제외한 부분 가져오기\n",
    "            image_name = os.path.splitext(os.path.basename(image_file_path))[0]\n",
    "        \n",
    "            # 해당 이미지 파일과 매칭되는 JSON 파일 찾기\n",
    "            if image_name in json_files:\n",
    "                json_file_path = json_files[image_name]\n",
    "                data_pairs.append((image_file_path, json_file_path))\n",
    "            else:\n",
    "                print(f\"JSON file not found for image: {image_file_path}\")\n",
    "        \n",
    "        return data_pairs\n",
    "\n",
    "    def create_detr_target(self, json_data):\n",
    "        annotations = json_data['annotations']\n",
    "        categories = {cat['id']: cat['name'] for cat in json_data['categories']}\n",
    "        \n",
    "        # 한글에서 영어로 라벨을 매핑하는 딕셔너리\n",
    "        label_mapping = {'화방': 0, '줄기': 1, '잎': 2, '열매': 3}  # 예시, 실제 매핑에 맞게 수정 필요\n",
    "\n",
    "        height = 1960  # 로즈 테스트시 고정값 사용\n",
    "        width = float(json_data['images'][0]['width'])\n",
    "\n",
    "        target = {\n",
    "            'boxes': [],\n",
    "            'labels': [],\n",
    "            'area': [],\n",
    "            'iscrowd': [],\n",
    "        }\n",
    "\n",
    "        for ann in annotations:\n",
    "            bbox = ann['bbox']\n",
    "            obj_name = categories[ann['category_id']]\n",
    "            \n",
    "            # 한글 카테고리 이름을 영어로 변환하여 매핑된 정수 레이블 얻기\n",
    "            label = label_mapping.get(obj_name, -1)  # 없는 경우에 대한 처리 필요\n",
    "\n",
    "            if label == -1:\n",
    "                continue  # 처리할 수 없는 경우 스킵하거나 예외 처리 필요\n",
    "            \n",
    "            # 바운딩 박스 좌표 변환 및 정규화\n",
    "            x_min = bbox[1] / width\n",
    "            y_min = (height-(bbox[0]+bbox[2])) / height\n",
    "            box_width = bbox[3] / width\n",
    "            box_height = bbox[2] / height\n",
    "            \n",
    "            target['boxes'].append([x_min, y_min, box_width, box_height])\n",
    "            target['area'].append(ann['area'])\n",
    "            target['iscrowd'].append(ann['isCrowd'])\n",
    "            target['labels'].append(label)\n",
    "\n",
    "        # 리스트를 텐서로 변환\n",
    "        target['boxes'] = torch.tensor(target['boxes'], dtype=torch.float32)\n",
    "        target['area'] = torch.tensor(target['area'], dtype=torch.float32)\n",
    "        target['iscrowd'] = torch.tensor(target['iscrowd'], dtype=torch.int64)\n",
    "        target['labels'] = torch.tensor(target['labels'], dtype=torch.int64)  # 클래스 레이블을 정수로 변환\n",
    "\n",
    "        return target\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        img = self.image_processor(image, return_tensors=\"pt\")\n",
    "        images = img['pixel_values'].clone().detach().to(torch.float32)\n",
    "        images = images.permute(0, 3, 1, 2)  # (batch_size, channels, height, width) 순으로 변환\n",
    "        return images\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path, json_path = self.data_pairs[index]\n",
    "\n",
    "        with open(json_path, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Preprocess the image using AutoImageProcessor\n",
    "        images = self.preprocess_image(img)\n",
    "\n",
    "        target = self.create_detr_target(json_data)\n",
    "\n",
    "        return images, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋과 변환 정의\n",
    "train_path = 'path_to_train_data_folder'\n",
    "val_path = 'path_to_validation_data_folder'\n",
    "test_path = 'path_to_test_data_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\py3_11\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.Resize((800, 1333)),  # 이미지 크기 조정\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 이미지 정규화\n",
    "])\n",
    "\n",
    "transform_val = T.Compose([\n",
    "    T.Resize((800, 1333)),  # 이미지 크기 조정\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 이미지 정규화\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching image and JSON files: 0it [00:00, ?it/s]\n",
      "Matching image and JSON files: 0it [00:00, ?it/s]\n",
      "Matching image and JSON files: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(test_path, transforms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 데이터 로더 설정\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py3_11\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 350\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\py3_11\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:143\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# 데이터셋 객체 생성\n",
    "train_dataset = CustomDataset(train_path, transforms=transform_train)\n",
    "val_dataset = CustomDataset(val_path, transforms=transform_val)\n",
    "test_dataset = CustomDataset(test_path, transforms=None)\n",
    "# 데이터 로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
